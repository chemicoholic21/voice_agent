<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Audio Streaming & Transcription Test</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            min-height: 100vh;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 30px;
            backdrop-filter: blur(10px);
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
        }
        
        h1 {
            text-align: center;
            margin-bottom: 30px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .controls {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-bottom: 30px;
        }
        
        button {
            padding: 12px 20px;
            font-size: 16px;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.2);
        }
        
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }
        
        .start-btn { background: #4CAF50; color: white; }
        .stop-btn { background: #f44336; color: white; }
        .transcription-btn { background: #2196F3; color: white; }
        .connect-btn { background: #FF9800; color: white; }
        
        .status {
            background: rgba(0,0,0,0.2);
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            min-height: 50px;
        }
        
        .messages {
            background: rgba(0,0,0,0.2);
            padding: 20px;
            border-radius: 8px;
            height: 300px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.4;
        }
        
        .message {
            margin-bottom: 8px;
            padding: 5px;
            border-radius: 4px;
        }
        
        .transcription {
            background: rgba(76, 175, 80, 0.3);
            border-left: 4px solid #4CAF50;
            font-weight: bold;
        }
        
        .error {
            background: rgba(244, 67, 54, 0.3);
            border-left: 4px solid #f44336;
        }
        
        .info {
            background: rgba(33, 150, 243, 0.3);
            border-left: 4px solid #2196F3;
        }
        
        .audio-info {
            margin-top: 20px;
            background: rgba(255, 255, 255, 0.1);
            padding: 15px;
            border-radius: 8px;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Real-Time Audio Streaming & Transcription</h1>
        
        <div class="controls">
            <button id="connectBtn" class="connect-btn" onclick="connect()">Connect WebSocket</button>
            <button id="startRecordingBtn" class="start-btn" onclick="startRecording()" disabled>Start Recording</button>
            <button id="stopRecordingBtn" class="stop-btn" onclick="stopRecording()" disabled>Stop Recording</button>
            <button id="startTranscriptionBtn" class="transcription-btn" onclick="startTranscription()" disabled>Start Transcription</button>
            <button id="stopTranscriptionBtn" class="transcription-btn" onclick="stopTranscription()" disabled>Stop Transcription</button>
        </div>
        
        <div class="status">
            <strong>Status:</strong> <span id="status">Disconnected</span>
        </div>
        
        <div class="messages" id="messages"></div>
        
        <div class="audio-info">
            <strong>Audio Format:</strong> 16kHz, 16-bit, Mono PCM (as required by AssemblyAI)<br>
            <strong>Instructions:</strong>
            <ol>
                <li>Click "Connect WebSocket" to establish connection</li>
                <li>Click "Start Transcription" to enable real-time transcription</li>
                <li>Allow microphone access when prompted</li>
                <li>Speak into your microphone to see live transcriptions</li>
                <li>Optionally, use "Start Recording" to also save audio to file</li>
            </ol>
        </div>
    </div>

    <script>
        let ws = null;
        let mediaRecorder = null;
        let audioContext = null;
        let source = null;
        let processor = null;
        let isRecording = false;
        let isTranscribing = false;
        
        const connectBtn = document.getElementById('connectBtn');
        const startRecordingBtn = document.getElementById('startRecordingBtn');
        const stopRecordingBtn = document.getElementById('stopRecordingBtn');
        const startTranscriptionBtn = document.getElementById('startTranscriptionBtn');
        const stopTranscriptionBtn = document.getElementById('stopTranscriptionBtn');
        const status = document.getElementById('status');
        const messages = document.getElementById('messages');
        
        function updateStatus(text) {
            status.textContent = text;
        }
        
        function addMessage(text, type = 'info') {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            messageDiv.textContent = `[${new Date().toLocaleTimeString()}] ${text}`;
            messages.appendChild(messageDiv);
            messages.scrollTop = messages.scrollHeight;
        }
        
        function connect() {
            try {
                ws = new WebSocket('ws://localhost:8001/ws');
                
                ws.onopen = function() {
                    updateStatus('Connected');
                    addMessage('WebSocket connected successfully!', 'info');
                    connectBtn.disabled = true;
                    startRecordingBtn.disabled = false;
                    startTranscriptionBtn.disabled = false;
                };
                
                ws.onmessage = function(event) {
                    const message = event.data;
                    addMessage(message, message.includes('TRANSCRIPT') ? 'transcription' : 'info');
                };
                
                ws.onclose = function() {
                    updateStatus('Disconnected');
                    addMessage('WebSocket disconnected', 'error');
                    connectBtn.disabled = false;
                    startRecordingBtn.disabled = true;
                    stopRecordingBtn.disabled = true;
                    startTranscriptionBtn.disabled = true;
                    stopTranscriptionBtn.disabled = true;
                };
                
                ws.onerror = function(error) {
                    addMessage('WebSocket error: ' + error, 'error');
                };
                
            } catch (error) {
                addMessage('Connection error: ' + error.message, 'error');
            }
        }
        
        function startRecording() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send('start_recording');
                isRecording = true;
                startRecordingBtn.disabled = true;
                stopRecordingBtn.disabled = false;
                addMessage('Recording started', 'info');
            }
        }
        
        function stopRecording() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send('stop_recording');
                isRecording = false;
                startRecordingBtn.disabled = false;
                stopRecordingBtn.disabled = true;
                addMessage('Recording stopped', 'info');
            }
        }
        
        async function startTranscription() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send('start_transcription');
                
                try {
                    // Request microphone access with 16kHz sample rate
                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });
                    
                    // Create audio context with 16kHz sample rate
                    audioContext = new AudioContext({ sampleRate: 16000 });
                    source = audioContext.createMediaStreamSource(stream);
                    
                    // Create script processor for real-time audio processing
                    processor = audioContext.createScriptProcessor(4096, 1, 1);
                    
                    processor.onaudioprocess = function(event) {
                        if (isTranscribing && ws && ws.readyState === WebSocket.OPEN) {
                            const inputBuffer = event.inputBuffer;
                            const inputData = inputBuffer.getChannelData(0);
                            
                            // Convert float32 to int16 (PCM 16-bit)
                            const int16Array = new Int16Array(inputData.length);
                            for (let i = 0; i < inputData.length; i++) {
                                int16Array[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7FFF;
                            }
                            
                            // Send audio data to WebSocket
                            ws.send(int16Array.buffer);
                        }
                    };
                    
                    source.connect(processor);
                    processor.connect(audioContext.destination);
                    
                    isTranscribing = true;
                    startTranscriptionBtn.disabled = true;
                    stopTranscriptionBtn.disabled = false;
                    addMessage('Real-time transcription started - speak now!', 'info');
                    
                } catch (error) {
                    addMessage('Microphone access error: ' + error.message, 'error');
                }
            }
        }
        
        function stopTranscription() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send('stop_transcription');
                
                if (processor) {
                    processor.disconnect();
                    processor = null;
                }
                if (source) {
                    source.disconnect();
                    source = null;
                }
                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }
                
                isTranscribing = false;
                startTranscriptionBtn.disabled = false;
                stopTranscriptionBtn.disabled = true;
                addMessage('Real-time transcription stopped', 'info');
            }
        }
        
        // Handle page unload
        window.addEventListener('beforeunload', function() {
            if (isTranscribing) stopTranscription();
            if (isRecording) stopRecording();
            if (ws) ws.close();
        });
    </script>
</body>
</html>
